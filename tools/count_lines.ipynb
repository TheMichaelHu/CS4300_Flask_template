{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import json\n",
    "import copy\n",
    "from slugify import slugify\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('./data/movies.csv')\n",
    "movie_titles_creds = np.array(credits[\"title\"].tolist())\n",
    "movies = pd.read_csv('./data/movies_data.csv')\n",
    "movie_titles_movies = np.array(movies[\"title\"].tolist())\n",
    "metadata_csv = pd.read_csv('./data/metadata.csv')\n",
    "movie_titles_metadata = np.array(metadata_csv[\"title\"].tolist())\n",
    "abs_path = os.path.abspath(\"mydir/myfile.txt\")\n",
    "new_path = abs_path[:abs_path.find('tools')] + 'app/data/movies/'\n",
    "\n",
    "gender_mapping = {0 : \"Other\", 1 : \"Female\", 2 : \"Male\"}\n",
    "\n",
    "ethnicities = pd.read_csv('./data/ethnicelebs.csv', header = None)\n",
    "actor_names = ethnicities[0].tolist()\n",
    "actor_ethnicities = ethnicities[1].tolist()\n",
    "\n",
    "races = pd.read_csv('./data/ethnicities_to_races.csv')\n",
    "ethnicity_mapping = np.array(races[\"ethnicity\"].tolist())\n",
    "race_mapping = np.array(races[\"race\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transcript(filename):\n",
    "\n",
    "    spaces_regex = re.compile(\"^(\\s*).*\")\n",
    "    location_regex = re.compile(\"^\\s*(INT\\.|EXT\\.)\")\n",
    "    line_list = []\n",
    "    transcript = []\n",
    "    characters = []\n",
    "    characters2 = []\n",
    "\n",
    "    text_file = open(filename, \"r\")\n",
    "    lines = text_file.readlines()\n",
    "    text_file.close()\n",
    "\n",
    "    num_lines = 0;\n",
    "    for l in lines:\n",
    "        li = l.strip(' \\n\\t\\r')\n",
    "        if li != \"\" and num_lines != 0:\n",
    "            c = re.sub(r'\\([^()]*\\)', '', li).strip(' \\n\\t\\r')\n",
    "            if (c in characters) and (c not in characters2):\n",
    "                characters2.append(c)\n",
    "            if c.isupper() and (not li.endswith(\" POV\")) and (\"INT.\" not in l) and (\"EXT.\" not in l) and (\"--\" not in l) and (\"_\" not in l) and (\"- DAY\" not in l) and (\"INTERIOR\" not in l) and (\"CLOSE ON\" != li) and (\"CUT TO\" != li) and (\"EXTERIOR\" not in l) and (\"NSERT \" not in l) and (\"BACK TO \" not in l) and (\"ACTION \" not in l) and (\"OMITTED\" not in l) and ('LATER THAT NIGHT -' not in l) and (\"ANOTHER ANGLE\" not in l) and (\"IN THE CAR\" not in l) and (\"IN THE LOT\" not in l) and (\"ACROSS THE \" not in l) and (\"THE END\" not in l) and (\"END CREDITS\" not in l) and (\"FADE OUT\" not in l) and (\":\" not in l) and (\"!\" not in l) and (\"?\" not in l) and ('\"' not in l) and (\"NEW ANGLE\" != li) and (\"CLOSEUP\" not in l) and (\"ANGLE ON TV\" != li) and (not c.endswith(\".\")) and (c not in characters):\n",
    "                characters.append(c)\n",
    "        elif li != \"\": \n",
    "            num_lines = 1\n",
    "\n",
    "    speaker = \"\";\n",
    "    utterance = \"\";\n",
    "    still_speaking = True\n",
    "    second_time = False\n",
    "    previous_spaces = 0\n",
    "\n",
    "    for l in lines:\n",
    "        li = l.strip(' \\n\\t\\r')\n",
    "        if li != \"\": \n",
    "            spmatch = spaces_regex.search(l)\n",
    "            spaces_number = len(spmatch.group(1))\n",
    "            ch = re.sub(r'\\([^()]*\\)', '', re.sub(r'\\[[^()]*\\]', '', li)).strip(' \\n\\t\\r')\n",
    "            if ch == \"\" or ch.startswith(\"(\") or ch.endswith(\")\"):\n",
    "                ch = \"\"\n",
    "            elif ((\"INT.\" in l or \"EXT.\" in l) and utterance != \"\") or li == \"THE END\":\n",
    "                transcript.append({'speaker': speaker, 'utterance': re.sub(r'\\[[^()]*\\]', '', utterance.strip())})\n",
    "                speaker = \"\"\n",
    "                utterance = \"\"\n",
    "                second_time = False \n",
    "            elif ch in characters2:\n",
    "                if utterance != \"\" and speaker != ch and speaker != \"\":\n",
    "                    second_time = False\n",
    "                    transcript.append({'speaker': speaker, 'utterance': re.sub(r'\\[[^()]*\\]', '', utterance.strip())})\n",
    "                    utterance = \"\"\n",
    "                elif speaker == ch:\n",
    "                    second_time = True\n",
    "                speaker = ch;\n",
    "                still_speaking = True\n",
    "                previous_spaces = 0\n",
    "            elif still_speaking == True and speaker != \"\":\n",
    "                if (spaces_number == previous_spaces or previous_spaces == 0):\n",
    "                    utterance += \" \" + li\n",
    "                    previous_spaces = spaces_number;\n",
    "                second_time = False                \n",
    "        elif utterance == \"\" and speaker != \"\":\n",
    "            still_speaking = True\n",
    "        elif utterance != \"\" and second_time == False:\n",
    "            still_speaking = False\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(transcript):\n",
    "    line_dict = dict()\n",
    "    \n",
    "    for i in np.arange(len(transcript)):\n",
    "        speaker = transcript[i]['speaker']\n",
    "        line = transcript[i]['utterance']\n",
    "        if speaker in line_dict.keys():\n",
    "            line_dict[speaker] += [line]\n",
    "        else:\n",
    "            line_dict[speaker] = [line]\n",
    "    \n",
    "    return line_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(imdb_id):\n",
    "    REVIEWS_KEY = \"b0d4c725e171d3cb40ded4d9ce2989b7\"\n",
    "    movie_id_request = \"https://api.themoviedb.org/3/find/\" + imdb_id + \"?api_key=\" + REVIEWS_KEY  + \"&external_source=imdb_id\"\n",
    "    try:\n",
    "        with urllib.request.urlopen(movie_id_request) as url:\n",
    "            movie_id_results = json.loads(url.read().decode())\n",
    "        movie_id = movie_id_results['movie_results'][0]['id']\n",
    "\n",
    "    except:\n",
    "        movie_id = \"N/A\"\n",
    "    if movie_id != \"N/A\":\n",
    "        review_request = \"https://api.themoviedb.org/3/movie/\" + str(movie_id) + \"/reviews?api_key=\" + REVIEWS_KEY\n",
    "        try:\n",
    "            with urllib.request.urlopen(review_request) as url:\n",
    "                results = json.loads(url.read().decode())['results']\n",
    "                reviews = [x['content'] for x in results]\n",
    "                return reviews\n",
    "        except:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_metadata(name, script):\n",
    "    metadata = dict()\n",
    "    movie_num = np.where(movie_titles_movies == name)\n",
    "    metadata_name = np.array(movies[\"title\"].tolist())[movie_num][0]\n",
    "    genres = json.loads(np.array(movies[\"genres\"].tolist())[movie_num][0])\n",
    "    metadata[\"genres\"] = [x[\"name\"].lower() for x in genres]\n",
    "    fname = script[:len(script)-4]\n",
    "    metadata[\"script\"] = fname[fname.rfind('/')+1:].lower()\n",
    "    metadata[\"id\"] = int(np.array(movies[\"id\"].tolist())[movie_num][0])\n",
    "    release_year = np.array(movies[\"release_date\"].tolist())[movie_num][0].split('-')[0]\n",
    "    metadata[\"release_yr\"] = release_year\n",
    "    metadata[\"rating\"] = str(np.array(movies[\"vote_average\"].tolist())[movie_num][0])\n",
    "    metadata[\"budget\"] = str(np.array(movies[\"budget\"].tolist())[movie_num][0])\n",
    "    metadata[\"box_office\"] = str(np.array(movies[\"revenue\"].tolist())[movie_num][0])\n",
    "    metadata[\"synopsis\"] = np.array(movies[\"overview\"].tolist())[movie_num][0]\n",
    "    metadata[\"num_awards\"] = 0\n",
    "    \n",
    "    try:\n",
    "        num = np.where(movie_titles_metadata == metadata_name)\n",
    "        metadata[\"name\"] = np.array(metadata_csv[\"title\"].tolist())[num][0]\n",
    "        metadata[\"review_score\"] = np.array(metadata_csv[\"review_score\"].tolist())[num][0]\n",
    "        metadata[\"poster_image_url\"] = np.array(metadata_csv[\"poster\"].tolist())[num][0]\n",
    "        imdbID = np.array(metadata_csv[\"imdbID\"].tolist())[num][0]\n",
    "        metadata[\"imdb_url\"] = \"https://www.imdb.com/title/\" + imdbID\n",
    "        metadata[\"imdb_reviews\"] = np.array(metadata_csv[\"reviews\"].tolist())[num][0]\n",
    "    \n",
    "    except:\n",
    "        metadata[\"name\"] = metadata_name\n",
    "        poster_title = metadata[\"name\"].lower()\n",
    "        poster_title = poster_title.replace(\":\", \"%3c\")\n",
    "        poster_title = poster_title.replace(\"&\", \"%26\")\n",
    "        poster_title = poster_title.replace(\"/\", \"%2f\")\n",
    "        poster_title = poster_title.replace(\",\", \"%2c\")\n",
    "        poster_title = poster_title.replace(\"+\", \"%2b\")\n",
    "        poster_title = '+'.join(poster_title.split(' '))\n",
    "        omdb_request = \"http://omdbapi.com/?apikey=\" + MY_KEY + \"&t=\" + poster_title + \"&y=\" + release_year\n",
    "        imdbID = \"\"\n",
    "    \n",
    "        try:\n",
    "            with urllib.request.urlopen(omdb_request) as url:\n",
    "                omdb_results = json.loads(url.read().decode())\n",
    "            metadata[\"review_score\"] = omdb_results[\"imdbRating\"]\n",
    "            metadata[\"poster_image_url\"] = omdb_results[\"Poster\"]\n",
    "            imdbID = omdb_results[\"imdbID\"]\n",
    "            metadata[\"imdb_url\"] = \"https://www.imdb.com/title/\" + imdbID\n",
    "            metadata[\"imdb_reviews\"] = get_reviews(imdbID)\n",
    "        except:\n",
    "            metadata[\"review_score\"] = \"N/A\"\n",
    "            metadata[\"poster_image_url\"] = \"N/A\"\n",
    "            metadata[\"imdb_url\"] = \"N/A\"\n",
    "            metadata[\"imdb_reviews\"] = []\n",
    "            \n",
    "        with open(\"./data/metadata.csv\", \"a\") as output:\n",
    "            writer = csv.writer(output, lineterminator='\\n')\n",
    "            writer.writerow([metadata[\"name\"], metadata[\"review_score\"], metadata[\"poster_image_url\"], imdbID, metadata[\"imdb_reviews\"]])\n",
    "        \n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    overall_compound = 0\n",
    "    for review in metadata[\"imdb_reviews\"]:\n",
    "        vs = analyzer.polarity_scores(review)\n",
    "        overall_compound += vs[\"compound\"]\n",
    "        \n",
    "    if len(metadata[\"imdb_reviews\"]) > 0:\n",
    "        overall_compound = overall_compound / len(metadata[\"imdb_reviews\"])\n",
    "        if(overall_compound) >= 0.05:\n",
    "            metadata[\"imdb_review_sentiment\"] = \"Positive\"\n",
    "        elif(overall_compound) < -0.05:\n",
    "            metadata[\"imdb_review_sentiment\"] = \"Negative\"\n",
    "        else:\n",
    "            metadata[\"imdb_review_sentiment\"] = \"Neutral\"\n",
    "    else:\n",
    "        metadata[\"imdb_review_sentiment\"] = \"Neutral\"\n",
    "\n",
    "    metadata[\"slug\"] = re.sub(r'[-\\s]+', '-', (re.sub(r'[^\\w\\s-]', '',metadata[\"name\"]).strip().lower()))\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cast_and_crew(name):\n",
    "    movie_num = np.where(movie_titles_creds == name)\n",
    "    cast = np.array(credits[\"cast\"].tolist())[movie_num][0]\n",
    "    crew = np.array(credits[\"crew\"].tolist())[movie_num][0]\n",
    "    return cast, crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_metadata(cast):\n",
    "    metadata = dict()\n",
    "    \n",
    "    char_list = json.loads(cast)\n",
    "    for person in char_list:\n",
    "        metadata[person['name']] = {'actor_id' : person['cast_id'], 'char_name' : person['character']}\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crew_metadata(crew):\n",
    "    metadata = dict()\n",
    "    crew_list = json.loads(crew)\n",
    "    for person in crew_list:\n",
    "        metadata[person['name']] = {'crew_id' : person['id'], 'job_name' : person['job']}\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfeatures(baby, B, FIX):\n",
    "    v = np.zeros(B)\n",
    "    for m in range(FIX):\n",
    "        featurestring = \"prefix\" + baby[:m]\n",
    "        v[hash(featurestring) % B] = 1\n",
    "        featurestring = \"suffix\" + baby[-1*m:]\n",
    "        v[hash(featurestring) % B] = 1\n",
    "    return v\n",
    "\n",
    "def name2features(filename, B=104729, FIX=5, LoadFile=True):\n",
    "    if LoadFile:\n",
    "        with open(filename, 'r') as f:\n",
    "            babynames = [x.rstrip() for x in f.readlines() if len(x) > 0]\n",
    "    else:\n",
    "        babynames = filename.split('\\n')\n",
    "    n = len(babynames)\n",
    "    X = np.zeros((n, B))\n",
    "    for i in range(n):\n",
    "        X[i,:] = hashfeatures(babynames[i], B, FIX)\n",
    "    return X\n",
    "\n",
    "def genTrainFeatures(dimension=128, fix=3):\n",
    "    Xgirls = name2features(\"./girls.train\", B=dimension, FIX=fix)\n",
    "    Xboys = name2features(\"./boys.train\", B=dimension, FIX=fix)\n",
    "    X = np.concatenate([Xgirls, Xboys])\n",
    "    Y = np.concatenate([-np.ones(len(Xgirls)), np.ones(len(Xboys))])\n",
    "    ii = np.random.permutation([i for i in range(len(Y))])\n",
    "    return X[ii, :], Y[ii]\n",
    "X,Y = genTrainFeatures(128)\n",
    "\n",
    "def naivebayesPY(x,y):\n",
    "    y = np.concatenate([y, [-1,1]])\n",
    "    n = len(y)\n",
    "    unique_elements, counts_elements = np.unique(y, return_counts=True)\n",
    "    neg = counts_elements[0] / n\n",
    "    pos = counts_elements[1] / n\n",
    "    return pos, neg\n",
    "pos,neg = naivebayesPY(X,Y)\n",
    "\n",
    "def naivebayesPXY(x,y):\n",
    "    n, d = x.shape\n",
    "    x = np.concatenate([x, np.ones((2,d))])\n",
    "    y = np.concatenate([y, [-1,1]])\n",
    "    n, d = x.shape\n",
    "    x_pos = x[np.where(y==1)]\n",
    "    x_neg = x[np.where(y==-1)]\n",
    "    x_pos_sum = np.sum(x_pos, axis=0)\n",
    "    x_neg_sum = np.sum(x_neg, axis=0)\n",
    "    x_pos_sum_denom = np.sum(x_pos_sum)\n",
    "    x_neg_sum_denom = np.sum(x_neg_sum)\n",
    "    posprob = np.array([x_pos_sum/x_pos_sum_denom])\n",
    "    negprob = np.array([x_neg_sum/x_neg_sum_denom])\n",
    "    return posprob, negprob\n",
    "posprob,negprob = naivebayesPXY(X,Y)\n",
    "\n",
    "def naivebayes(x,y,xtest):\n",
    "    ppos, pneg = naivebayesPY(x,y)\n",
    "    theta_pos, theta_neg = naivebayesPXY(x,y)\n",
    "    log_theta_pos = np.log(theta_pos)\n",
    "    log_theta_neg = np.log(theta_neg)\n",
    "    return (np.sum(xtest * log_theta_pos) + np.log(ppos) - (np.sum(xtest * log_theta_neg) + np.log(pneg)))\n",
    "p = naivebayes(X,Y,X[0,:])\n",
    "\n",
    "def naivebayesCL(x,y):\n",
    "    n, d = x.shape\n",
    "    ppos, pneg = naivebayesPY(x,y)\n",
    "    theta_pos, theta_neg = naivebayesPXY(x,y)\n",
    "    log_theta_pos = np.log(theta_pos)\n",
    "    log_theta_neg = np.log(theta_neg)\n",
    "    w = log_theta_pos - log_theta_neg\n",
    "    b = np.log(ppos) - np.log(pneg)\n",
    "    return w,b\n",
    "w,b = naivebayesCL(X,Y)\n",
    "\n",
    "def classifyLinear(x,w,b=0):\n",
    "    w = w.reshape(-1)\n",
    "    class_raw = np.dot(w.T, x.T) + b\n",
    "    result = np.array(np.sign(class_raw))\n",
    "    np.place(result, result == 0, [-1])\n",
    "    return result\n",
    "DIMS = 128\n",
    "X,Y = genTrainFeatures(DIMS)\n",
    "w,b=naivebayesCL(X,Y)\n",
    "error = np.mean(classifyLinear(X,w,b) != Y)\n",
    "\n",
    "def classify_name(name):\n",
    "    name = name.capitalize()\n",
    "    xtest = name2features(name, B = DIMS, LoadFile = False)\n",
    "    pred = classifyLinear(xtest,w,b)[0]\n",
    "    if pred > 0:\n",
    "        return \"Male\"\n",
    "    else:\n",
    "        return \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_dict(cast, lines):\n",
    "    char_list = json.loads(cast)\n",
    "    char_choices = [x['character'] for x in char_list]\n",
    "    char_choices_dict = {idx: el for idx, el in enumerate(char_choices)}\n",
    "    \n",
    "    gender_dict = dict()\n",
    "    gender_dict_by_lines = dict()\n",
    "    \n",
    "    some_counter = 0\n",
    "    \n",
    "    for speaker in lines.keys():\n",
    "        some_counter += 1\n",
    "        match = process.extractOne(speaker, char_choices_dict)\n",
    "        if not (match is None) and match[1] != 0:\n",
    "            match_index = match[2]\n",
    "            final_match = char_list[match_index]\n",
    "            char_choices_dict.pop(match_index, None)\n",
    "            gender = gender_mapping[final_match['gender']]\n",
    "            if gender == 'Other':\n",
    "                overall_gender = dict()\n",
    "                char_gender = classify_name(final_match['character'])\n",
    "                speaker_gender = classify_name(speaker)\n",
    "                if char_gender in overall_gender.keys():\n",
    "                    overall_gender[char_gender] += 1\n",
    "                else:\n",
    "                    overall_gender[char_gender] = 1\n",
    "                if speaker_gender in overall_gender.keys():\n",
    "                    overall_gender[speaker_gender] += 1\n",
    "                else:\n",
    "                    overall_gender[speaker_gender] = 1\n",
    "                gender = max(overall_gender.keys(), key=(lambda k : overall_gender[k]))\n",
    "            if final_match['character'] not in gender_dict.keys():\n",
    "                gender_dict[final_match['character']] = speaker, final_match['name'], gender, final_match['cast_id']\n",
    "            else:\n",
    "                gender_dict[final_match['character'] + str(some_counter)] = speaker, final_match['name'], gender, final_match['cast_id']\n",
    "        else:\n",
    "            if speaker not in gender_dict.keys() and speaker not in gender_dict_by_lines.keys():\n",
    "                gender_dict_by_lines[speaker] = speaker, 'N/A', classify_name(speaker), \"N/A\"\n",
    "            else:\n",
    "                gender_dict_by_lines[speaker + str(some_counter)] = speaker, 'N/A', classify_name(speaker), \"N/A\"\n",
    "                \n",
    "    new_gender_dict = copy.deepcopy(gender_dict)\n",
    "    new_gender_dict.update(gender_dict_by_lines)\n",
    "    \n",
    "    return gender_dict, new_gender_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crew_gender_dict(crew):\n",
    "    crew_list = json.loads(crew)\n",
    "    gender_dict = dict()\n",
    "    \n",
    "    for member in crew_list:\n",
    "        name = member['name']\n",
    "        given_gender = gender_mapping[member['gender']]\n",
    "        classified_gender = classify_name(name)\n",
    "        gender = given_gender\n",
    "        if gender == \"Other\":\n",
    "            gender = classified_gender\n",
    "        \n",
    "        gender_dict[name] = gender\n",
    "    \n",
    "    return gender_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ethnicity_dict(genders):\n",
    "    ethnicity_dict = dict()\n",
    "    for character in genders.keys():\n",
    "        speaker, name, gender, actor_id = genders[character]\n",
    "        actor = '-'.join(name.lower().split(' '))\n",
    "        try:\n",
    "            actor_ethnicity = actor_ethnicities[actor_names.index(actor)]\n",
    "            if(type(actor_ethnicity) != str):\n",
    "                actor_ethnicity = \"N/A\"\n",
    "            ethnicity_dict[character] = speaker, name, actor_ethnicity\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "    return ethnicity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gender(lines, genders):\n",
    "    by_line = dict()\n",
    "    by_char = dict()\n",
    "    \n",
    "    total_lines = 0\n",
    "    total_chars = len(genders.keys())\n",
    "    \n",
    "    for char in genders.keys():\n",
    "        speaker, name, gender, actor_id = genders[char]\n",
    "        num_lines = len(lines[speaker])\n",
    "        total_lines += num_lines\n",
    "        \n",
    "        if gender in by_line.keys():\n",
    "            by_line[gender] += num_lines\n",
    "            by_char[gender] += 1\n",
    "        else:\n",
    "            by_line[gender] = num_lines\n",
    "            by_char[gender] = 1\n",
    "            \n",
    "    for char in by_line.keys():\n",
    "        by_line[char] = round(by_line[char] / total_lines, 2)\n",
    "        by_char[char] = round(by_char[char] / total_chars, 2)\n",
    "        \n",
    "    try:\n",
    "        by_line[\"Male\"] = by_line[\"Male\"]\n",
    "    except KeyError:\n",
    "        by_line[\"Male\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_line[\"Female\"] = by_line[\"Female\"]\n",
    "    except KeyError:\n",
    "        by_line[\"Female\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_line[\"Other\"] = by_line[\"Other\"]\n",
    "    except KeyError:\n",
    "        by_line[\"Other\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_char[\"Male\"] = by_char[\"Male\"]\n",
    "    except KeyError:\n",
    "        by_char[\"Male\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_char[\"Female\"] = by_char[\"Female\"]\n",
    "    except KeyError:\n",
    "        by_char[\"Female\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_char[\"Other\"] = by_char[\"Other\"]\n",
    "    except KeyError:\n",
    "        by_char[\"Other\"] = 0\n",
    "        \n",
    "    by_line = {\"Male\" : by_line[\"Male\"], \"Female\" : by_line[\"Female\"], \"Other\" : by_line[\"Other\"]}\n",
    "    by_char = {\"Male\" : by_char[\"Male\"], \"Female\" : by_char[\"Female\"], \"Other\" : by_char[\"Other\"]}\n",
    "    \n",
    "    return by_line, by_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_crew_gender(crew_genders):\n",
    "    total_crew = len(crew_genders.keys())\n",
    "    by_member = dict()\n",
    "    \n",
    "    for member in crew_genders.keys():\n",
    "        gender = crew_genders[member]\n",
    "        \n",
    "        if gender in by_member.keys():\n",
    "            by_member[gender] += 1\n",
    "        else:\n",
    "            by_member[gender] = 1\n",
    "            \n",
    "    for member in by_member.keys():\n",
    "        by_member[member] = round(by_member[member] / total_crew, 2)\n",
    "        \n",
    "    try:\n",
    "        by_member[\"Male\"] = by_member[\"Male\"]\n",
    "    except KeyError:\n",
    "        by_member[\"Male\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_member[\"Female\"] = by_member[\"Female\"]\n",
    "    except KeyError:\n",
    "        by_member[\"Female\"] = 0\n",
    "        \n",
    "    try:\n",
    "        by_member[\"Other\"] = by_member[\"Other\"]\n",
    "    except KeyError:\n",
    "        by_member[\"Other\"] = 0\n",
    "        \n",
    "    by_member = {\"Male\" : by_member[\"Male\"], \"Female\" : by_member[\"Female\"], \"Other\" : by_member[\"Other\"]}\n",
    "    \n",
    "    return by_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ethnicity(lines, ethnicities):\n",
    "    by_line = dict()\n",
    "    by_char = dict()\n",
    "    race_dict = dict()\n",
    "    \n",
    "    total_lines = 0\n",
    "    total_chars = len(ethnicities.keys())\n",
    "    \n",
    "    for char in ethnicities.keys():\n",
    "        speaker, name, ethnicity = ethnicities[char]\n",
    "        num_lines = len(lines[speaker])\n",
    "        total_lines += num_lines\n",
    "        \n",
    "        char_ethnicities = re.findall(r'[a-zA-Z]+', ethnicity)\n",
    "        char_ethnicities = [x for x in char_ethnicities if x[0].isupper()]\n",
    "        char_race = set()\n",
    "         \n",
    "        for e in char_ethnicities:\n",
    "            try:\n",
    "                race_num = np.where(ethnicity_mapping == e)\n",
    "                races = race_mapping[race_num]\n",
    "                if len(races) > 0:\n",
    "                    char_race.add(races[0])\n",
    "            except Error:\n",
    "                pass\n",
    "        \n",
    "        race_dict[char] = \", \".join(char_race)     \n",
    "        \n",
    "        \n",
    "        for race in char_race:\n",
    "            if race in by_line.keys():\n",
    "                by_line[race] += num_lines\n",
    "                by_char[race] += 1\n",
    "            else:\n",
    "                by_line[race] = num_lines\n",
    "                by_char[race] = 1\n",
    "                \n",
    "    for char in by_line.keys():\n",
    "        by_line[char] = round(by_line[char] / total_lines, 2)\n",
    "        by_char[char] = round(by_char[char] / total_chars, 2)\n",
    "            \n",
    "    return by_line, by_char, race_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_female_speaker(transcript, genders, start_loc):\n",
    "    #genders = bechdel_genders in analyze_bechdel\n",
    "    #start_loc = where in transcript to start looking\n",
    "    #returns index of transcript with next female speaker if exists and -1 otherwise\n",
    "    \n",
    "    if start_loc >= len(transcript):\n",
    "        return -1\n",
    "    \n",
    "    else:\n",
    "        curr_transcript = transcript[start_loc:]\n",
    "        offset = 0\n",
    "        while offset < len(curr_transcript):\n",
    "            curr_speaker = curr_transcript[offset]['speaker']\n",
    "            curr_gender = genders[curr_speaker]\n",
    "            if curr_gender != \"Female\":\n",
    "                offset += 1\n",
    "            else:\n",
    "                break\n",
    "        if offset == len(curr_transcript):\n",
    "            return -1\n",
    "        else:\n",
    "            return start_loc + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_female_conversation(transcript, genders, start_loc):\n",
    "    \n",
    "    if start_loc >= len(transcript):\n",
    "        return [], -1\n",
    "    curr_transcript = transcript[start_loc:]\n",
    "    \n",
    "    index = 0\n",
    "    conversation = []\n",
    "    names = set()\n",
    "    while index < len(curr_transcript):\n",
    "        curr_speaker = curr_transcript[index]['speaker']\n",
    "        curr_gender = genders[curr_speaker]\n",
    "        if curr_gender == \"Female\":\n",
    "            names.add(curr_speaker)\n",
    "        if curr_gender != \"Female\":\n",
    "            if len(conversation) <= 1 or len(names) < 2:\n",
    "                return [], start_loc + index\n",
    "            else:\n",
    "                return conversation, start_loc + index\n",
    "        else:\n",
    "            conversation.append(curr_transcript[index])\n",
    "            index += 1\n",
    "    \n",
    "    if len(conversation) <= 1:\n",
    "        return [], start_loc + index\n",
    "    else:\n",
    "        return conversation, start_loc + index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_conversation(conversation, genders):\n",
    "    \n",
    "    genders_by_speaker = dict()\n",
    "    genders_by_character = dict()\n",
    "    \n",
    "    for name in genders.keys():\n",
    "        speaker, _, gender, _ = genders[name]\n",
    "        genders_by_speaker[speaker] = gender\n",
    "        genders_by_character[name] = gender\n",
    "        \n",
    "    merged_dict = genders_by_speaker.copy()\n",
    "    merged_dict.update(genders_by_character)\n",
    "    \n",
    "    name_choices = list(merged_dict.keys())\n",
    "    \n",
    "    male_words = ['he', 'him', 'his', 'himself', 'boy', 'boys', 'man', 'men', 'husband', 'son', 'father', 'brother', 'dad']\n",
    "    all_words = set() \n",
    "    for line in conversation:\n",
    "        words = set(re.findall(r'\\w+', line['utterance']))\n",
    "        all_words.update(words)\n",
    "        \n",
    "    word_list = list(all_words)\n",
    "    uppercase_words = [x for x in word_list if len(x) > 0 and x[0].isupper()]\n",
    "    lowercase_words = [x.lower() for x in word_list]\n",
    "    \n",
    "    uses_pronouns = any(x in male_words for x in lowercase_words)\n",
    "    uses_names = False\n",
    "    \n",
    "    for word in uppercase_words:\n",
    "        match = process.extractOne(word, name_choices)\n",
    "        if not match is None:\n",
    "            speaker, _ = match\n",
    "            name_choices.remove(speaker)\n",
    "            if speaker in genders_by_speaker.keys():\n",
    "                gender = genders_by_speaker[speaker]\n",
    "            else:\n",
    "                gender = genders_by_character[speaker]\n",
    "        else:\n",
    "            gender = classify_name(word)\n",
    "            has_male_markers = any(x.lower() in ['man', 'boy', 'men', 'boys', 'guy', 'guys'] for x in word.split(' '))\n",
    "            has_female_markers = any(x.lower() in ['woman', 'girl', 'women', 'girls'] for x in speaker.split(' '))\n",
    "            if gender == 'Male' or (has_male_markers and not has_female_markers):\n",
    "                gender = 'Male'\n",
    "        \n",
    "        if gender == 'Male':\n",
    "            uses_names = True\n",
    "            break\n",
    "        \n",
    "    return not (uses_pronouns or uses_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bechdel(transcript, genders):\n",
    "    \n",
    "    bechdel_genders = dict()\n",
    "    \n",
    "    for g in genders.keys():\n",
    "        speaker, _, gender, _ = genders[g]\n",
    "        bechdel_genders[speaker] = gender\n",
    "        \n",
    "        \n",
    "    if(len(transcript) == 0):\n",
    "        return dict(), False\n",
    "    \n",
    "    else:\n",
    "        index = find_next_female_speaker(transcript, bechdel_genders, 0)\n",
    "        while(index != -1 and index < len(transcript)):\n",
    "            conversation, end_index = find_female_conversation(transcript, bechdel_genders, index)\n",
    "            end_index += 1\n",
    "            if len(conversation) == 0:\n",
    "                index = find_next_female_speaker(transcript, bechdel_genders, end_index)\n",
    "            else:\n",
    "                valid_conversation = analyze_conversation(conversation, genders)\n",
    "                if valid_conversation:\n",
    "                    return conversation, True\n",
    "                else:\n",
    "                    index = find_next_female_speaker(transcript, bechdel_genders, end_index)\n",
    "        return dict(), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_screentime(lines, genders):\n",
    "    total_lines = 0\n",
    "    screentime_dict = dict()\n",
    "    \n",
    "    for char in genders.keys():\n",
    "        speaker, name, _, _ = genders[char]\n",
    "        num_lines = len(lines[speaker])\n",
    "        total_lines += num_lines\n",
    "        screentime_dict[name] = num_lines\n",
    "    \n",
    "    for name in screentime_dict.keys():\n",
    "        screentime_dict[name] = round(screentime_dict[name] / total_lines, 2)\n",
    "        \n",
    "    return screentime_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_metadata(lines, genders, races, screen_time):\n",
    "    \n",
    "    metadata = dict()\n",
    "    \n",
    "    for char in genders.keys():\n",
    "        speaker, name, gender, actor_id = genders[char]\n",
    "        race = \"N/A\"\n",
    "        if char in races.keys():\n",
    "            race = races[char]\n",
    "        time = screen_time[name]\n",
    "        metadata[name] = {\"actor_id\" : str(actor_id), \"char_name\" : speaker.capitalize(), \"screen_time\" : time, \"race\" : race, \"gender\" : gender}\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distr_metadata(g_line, g_char, g_crew, r_line, r_char):\n",
    "    metadata = dict()\n",
    "    \n",
    "    metadata[\"gender_dist\"] = {\n",
    "        \"by_movie\": {k.lower(): v for k, v in g_char.items()},\n",
    "        \"by_line\": {k.lower(): v for k, v in g_line.items()},\n",
    "        \"by_crew\" : {k.lower(): v for k, v in g_crew.items()}}\n",
    "    metadata[\"race_dist\"] = {\n",
    "        \"by_movie\": {k.lower(): v for k, v in r_char.items()},\n",
    "        \"by_line\": {k.lower(): v for k, v in r_line.items()}\n",
    "    }\n",
    "    metadata[\"stereotype_dist\"] = {\"by_movie\" : [[\"Stereotypical\", 0], [\"Not stereotypical\", 1]],\n",
    "                                   \"by_line\" : [[\"Stereotypical\", 0], [\"Not stereotypical\", 1]]}\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bechdel_metadata(transcript, genders):\n",
    "    metadata = dict()\n",
    "    \n",
    "    conversation, passes = analyze_bechdel(transcript, genders)\n",
    "    metadata[\"passes\"] = passes\n",
    "    metadata[\"conversation\"] = conversation\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_json(movie, script_path):\n",
    "    \"\"\"\n",
    "    writes movie json to ./data/parsed_scripts/[movie_slug].json\n",
    "    \"\"\"\n",
    "\n",
    "    movie_metadata = get_movie_metadata(movie, script_path)    \n",
    "    \n",
    "    movie_cast, movie_crew = get_cast_and_crew(movie)\n",
    "    actor_metadata = get_actor_metadata(movie_cast)\n",
    "    crew_metadata = get_crew_metadata(movie_crew)\n",
    "    transcript = parse_transcript(script_path)\n",
    "    line_dict = get_lines(transcript)\n",
    "    gender_dict, gender_dict_by_lines = get_gender_dict(movie_cast, line_dict)\n",
    "    \n",
    "    crew_gender_dict = get_crew_gender_dict(movie_crew)\n",
    "    ethnicity_dict = get_ethnicity_dict(gender_dict)\n",
    "    gender_by_line, gender_by_char = analyze_gender(line_dict, gender_dict_by_lines)\n",
    "    gender_by_crew = analyze_crew_gender(crew_gender_dict)\n",
    "    race_by_line, race_by_char, race_dict = analyze_ethnicity(line_dict, ethnicity_dict)\n",
    "    screen_time = analyze_screentime(line_dict, gender_dict)\n",
    "    \n",
    "    \n",
    "    char_metadata = get_char_metadata(line_dict, gender_dict, race_dict, screen_time)\n",
    "    distribution_metadata = get_distr_metadata(gender_by_line, gender_by_char, gender_by_crew, race_by_line, race_by_char)\n",
    "    bechdel_metadata = get_bechdel_metadata(transcript, gender_dict_by_lines)\n",
    "    \n",
    "    metadata = {\"movie_metadata\" : movie_metadata, \n",
    "                \"actor_metadata\" : actor_metadata,\n",
    "                \"crew_metadata\" : crew_metadata,\n",
    "                \"char_metadata\" : char_metadata, \n",
    "                \"distribution_metadata\" : distribution_metadata,\n",
    "                \"bechdel_metadata\" : bechdel_metadata}\n",
    "    \n",
    "    file = script_path[:-4]\n",
    "    file = os.path.dirname(file).replace(\"/scripts\", \"/parsed_scripts\") + \"/%s.json\" % movie_metadata[\"slug\"]\n",
    "    \n",
    "    target_dir = os.path.dirname(file)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    with open(file, 'w+') as outfile:\n",
    "        json.dump(metadata, outfile, indent=4, sort_keys=True)\n",
    "    \n",
    "    # also write to app data\n",
    "    with open(\"../app/data/movies/%s.json\" % movie_metadata[\"slug\"], 'w+') as outfile:\n",
    "        json.dump(metadata, outfile, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid movies: 757\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "saved jsons: 757\n"
     ]
    }
   ],
   "source": [
    "MY_KEY = \"8b0aeb00\"\n",
    "REVIEWS_KEY = \"b0d4c725e171d3cb40ded4d9ce2989b7\"\n",
    "transcripts = os.listdir(\"./data/scripts\")\n",
    "\n",
    "def parse_title(title):\n",
    "    title = title[:-4].replace(\"-\", \" \")\n",
    "    if title[-5:] == \", The\":\n",
    "        title = \"The \" + title[:-5] \n",
    "    return title\n",
    "\n",
    "tran_movies = [parse_title(title) for title in transcripts]\n",
    "\n",
    "with open('./data/movies.txt') as f:\n",
    "    all_movies = f.read().splitlines()\n",
    "    \n",
    "valid_movies = set([])\n",
    "for index in np.arange(len(all_movies)):\n",
    "    for movie in all_movies:\n",
    "        clean_tran_movie = re.sub(r'\\W+', '', all_movies[index]).lower()\n",
    "        clean_cred_movie = re.sub(r'\\W+', '', movie).lower()\n",
    "        if clean_tran_movie == clean_cred_movie[:len(clean_tran_movie)]:\n",
    "            valid_movies.add(movie)\n",
    "\n",
    "multiple_matches = []\n",
    "removed_movies = set()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for tran_movie_index in np.arange(len(tran_movies)):\n",
    "    \n",
    "    matching_movie = set()\n",
    "\n",
    "    for movie in valid_movies:\n",
    "        \n",
    "        clean_tran_movie = re.sub(r'\\W+', '', tran_movies[tran_movie_index]).lower()\n",
    "        clean_cred_movie = re.sub(r'\\W+', '', movie).lower()\n",
    "        \n",
    "        if clean_tran_movie == clean_cred_movie:\n",
    "            \n",
    "            matching_movie = set()\n",
    "            matching_movie.add(movie)\n",
    "            break\n",
    "            \n",
    "        elif clean_tran_movie == clean_cred_movie[:len(clean_tran_movie)]:\n",
    "            \n",
    "            matching_movie.add(movie)\n",
    "\n",
    "    if len(matching_movie) == 1:\n",
    "        \n",
    "        script_path = \"./data/scripts/\" + transcripts[tran_movie_index]\n",
    "        movie_name = matching_movie.pop()\n",
    "        removed_movies.add(movie_name)\n",
    "        get_metadata_json(movie_name, script_path)\n",
    "\n",
    "    if len(matching_movie) > 1:\n",
    "        \n",
    "        script_path = \"./data/scripts/\" + transcripts[tran_movie_index]\n",
    "        multiple_matches = multiple_matches + [(script_path, matching_movie, clean_tran_movie)]\n",
    "\n",
    "for i in np.arange(len(multiple_matches)):\n",
    "    \n",
    "    script_path, movie_name, script_name = multiple_matches[i]\n",
    "    movie_name = list(movie_name - removed_movies)\n",
    "    script_name_len = len((script_path[15:])[:-4])\n",
    "    final_movie = [movie for movie in movie_name if len(movie) >= script_name_len]\n",
    "    \n",
    "    if len(final_movie) != 0:\n",
    "        \n",
    "        match = process.extractOne(script_name, final_movie)\n",
    "    \n",
    "        if not match is None:\n",
    "        \n",
    "            final_movie = match[0]\n",
    "            removed_movies.add(final_movie)\n",
    "            get_metadata_json(final_movie, script_path)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            final_movie = final_movie[0]\n",
    "            get_metadata_json(final_movie, script_path)            \n",
    "\n",
    "    else:\n",
    "        \n",
    "        match = process.extractOne(script_name, movie_name)\n",
    "        \n",
    "        if not match is None:\n",
    "            \n",
    "            final_movie = match[0]\n",
    "            removed_movies.add(final_movie)\n",
    "            get_metadata_json(final_movie, script_path)  \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if len(movie_name) > 0:\n",
    "                \n",
    "                final_movie = min(movie_name, key=len)\n",
    "                removed_movies.add(final_movie)\n",
    "                get_metadata_json(final_movie, script_path)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
